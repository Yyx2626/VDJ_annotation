# VDJ_annotation
 Two pipelines and supporting scripts for VDJ annotation of HTGTS tlx files, including:
- iteratively estimate D usage in VDJ joins,
- annotate productivity according to observed part of each read

Author: Adam Yongxin Ye @ Boston Children's Hospital / Harvard Medical School


## Setup

The scripts are command-line perl and python scripts, with little dependence on other packages;  
except for `yyx_annotate_tlx_midD_LCS.20190116.py`, which `import Bio.SeqIO` ([Biopython](https://biopython.org/));  
and `yyx_annotate_HTGTS_VDJ_pipeline.20200219.py` needs to call `bedtools` and `python3`.

They should be able to run in any modern Linux or Mac platform;  
or you might need to first install perl and python 3 for your platform.

To use the scripts, just download the scripts and put/unzipped in a folder.  
You can rename the folder with any name you like, such as `VDJ_annotation_scripts`.

When executing the following Pipeline 1, just replace the command-line argument `<scripts_dir>` with the path of the folder.


## Pipeline 1. D usage in VDJ joins

### Step 1. annotate HTGTS tlx files

#### yyx_annotate_HTGTS_VDJ_pipeline.20200219.py  or  yyx_annotate_HTGTS_VDJ_pipeline.20220429.py
```
python3 yyx_annotate_HTGTS_VDJ_pipeline.20200219.py
	<VDJ_RSS_40.bed> <D.fa> <scripts_dir> <input.tlx> <output_prefix>
```
or the updated one (no dependency on Biopython and bedtools anymore)
```
python3 yyx_annotate_HTGTS_VDJ_pipeline.20220429.py
	<VDJ_RSS_40.bed> <D.fa> <scripts_dir> <input.tlx> <output_prefix>
```

Input:

- `<input.tlx>`  generated by HTGTS pipeline (<https://robinmeyers.github.io/transloc_pipeline/>)

- `<scripts_dir>`  should contain the script files called by this pipeline

  for `yyx_annotate_HTGTS_VDJ_pipeline.20200219.py`
  
  - `Yyx_check_col_num.pl`
  - `yyx_tlx2bed.20200126.py`
  - `yyx_sequence_segment_tlx.20181221.py`
  - `yyx_annotate_tlx_with_intersectBedResults.20181223.py`
  - `yyx_annotate_tlx_midD_LCS.20190116.py` (need Biopython)
  - `yyx_uniq_count_and_merge.20190111.py`
  - `yyx_show_or_skip_or_retrieve_columns.20190128.py`
  
  for `yyx_annotate_HTGTS_VDJ_pipeline.20220429.py`
  
  - `yyx_tlx_seq_seg_and_bed_anno.20220429.pl`
  - `yyx_annotate_tlx_midD_LCS.20220429.pl` (remove dependency of Biopython)

- `<VDJ_RSS_40.bed>`  contains the genomic coordinate range near RSS for each V/D/J segment

  - will used by `yyx_annotate_tlx_with_intersectBedResults.20181223.py`

- `<D.fa>`  contains the sequences of D segments, for

  - will used by `yyx_annotate_tlx_midD_LCS.20190116.py`
  
Output:  (where `yyyyMMdd` is the executing date)

- `<output_prefix>.intersectBed_annotated.yyyyMMdd.tlx`

  will append columns of
  - pre, bait, mid, prey, post sequences
  - \*_overlap_bps and \*_overlap_features  for junction, prey and bait

- `<output_prefix>.annotate_tlx_midD_LCS.yyyyMMdd.tlx`

  will append columns of  pre, bait, mid, prey, post, mid_D_score, mid_D_annotate
  
  for mid_D_annotate column, '(rC)' means reverse complement (orientation of D in the read)

- `<output_prefix>.HTGTS_VDJ_annotated.yyyyMMdd.tsv`

  final output tsv (tab-separated values) format file
  
  compared to `<input.tlx>`, append 5+6+2=13 columns
  - pre, bait, mid, prey, post (sequences) : 5 columns
  - \*_overlap_bps and \*_overlap_features  for junction, prey and bait : 3\*2=6 columns
  - mid_D_score and mid_D_annotate : 2 columns

`yyx_annotate_HTGTS_VDJ_pipeline.20200219.py` will sequentially call:

- `Yyx_check_col_num.pl`  to check the number of columns of <input.tlx>

- `yyx_tlx2bed.20200126.py`  to convert tlx to bed format for junction, prey, and bait

  - Output: `<output_prefix>.*.yyyyMMdd.tmp.bed` and `<output_prefix>.*.yyyyMMdd.bed`  
    (these intermediate files will be automatically removed)

- `yyx_sequence_segment_tlx.20181221.py`  to retrieve the segmented sequence (pre, bait, mid, prey, post) for each read

  - Output: `<output_prefix>.sequence_segmented.yyyyMMdd.tlx`  
    (this intermediate file will be automatically removed)

- `yyx_annotate_tlx_with_intersectBedResults.20181223.py`  to annotate tlx junction/prey/bait overlapping with `<VDJ_RSS_40.bed>`

  - Output: `<output_prefix>.intersectBed_annotated.yyyyMMdd.tlx`

- `yyx_annotate_tlx_midD_LCS.20190116.py`  to annotate mid by align to <D.fa> by longest continuous substring (LCS) algorithm

  - Output: `<output_prefix>.annotate_tlx_midD_LCS.yyyyMMdd.tlx`

- `yyx_uniq_count_and_merge.20190111.py`  to merge the annotation results above

  - Output: `<output_prefix>.HTGTS_annotate_merged.yyyyMMdd.tsv`  
    (this intermediate file will be automatically removed)

- `yyx_show_or_skip_or_retrieve_columns.20190128.py`  to skip some useless columns and output the final output tsv file

  - Output: `<output_prefix>.HTGTS_VDJ_annotated.yyyyMMdd.tsv`

Alternatively, the updated `yyx_annotate_HTGTS_VDJ_pipeline.20200219.py` will sequentially call:

- `yyx_tlx_seq_seg_and_bed_anno.20220429.pl` \
  to retrieve the segmented sequence (pre, bait, mid, prey, post) for each read, \
  and also annotate tlx junction/prey/bait overlapping with `<VDJ_RSS_40.bed>`

- `yyx_annotate_tlx_midD_LCS.20220429.pl`  to annotate mid by align to <D.fa> by longest continuous substring (LCS) algorithm


### Step 2. iteratively estimate D usage in VDJ joins

#### yyx_reannotate_VDJ_mid_D_usage_iteration_pipeline.20200319.pl
```
perl yyx_reannotate_VDJ_mid_D_usage_iteration_pipeline.20200319.pl
	<scripts_dir> <HTGTS_VDJ_annotated.tsv> <output_prefix> <mm9|mm9AJ>
	[iter_num (default:9)] [allowed_possible_D_num (default:99)]
	[init_ref_D_usage.tsv (default:even_probabilities]
```

Input: 

- `<scripts_dir>`  should contain the script file `yyx_reannotate_calculate_mid_D_usage.20200319.pl` called by this pipeline

- `<HTGTS_VDJ_annotated.tsv>`  generated by yyx_annotate_HTGTS_VDJ_pipeline.20200219.py

- `<mm9|mm9AJ>`  whether for mm9 (B6 mouse) or mm9_AJ851868ins (129 mouse) genome

- `[init_ref_D_usage.tsv]`  two columns: D, usage(%)

Output:

- `<output_prefix>.allow_*.iter_*.D_reannotated.tsv`
- `<output_prefix>.allow_*.iter_*.D_usage.tsv`

`yyx_reannotate_VDJ_mid_D_usage_iteration_pipeline.20200319.pl` will iteratively call (for `[iter_num]` times)

- `yyx_reannotate_calculate_mid_D_usage.20200319.pl`  
  which will focus on VDJ joins (Column junction_overlap_features starts with IGHV), 
  assign ambiguous D segments according to  `[init_ref_D_usage.tsv]`,
  then sum up D assignment to estimate D usage in VDJ joins


Later, you may also use some bash loops like below, 
to rearrange the final `<output_prefix>.allow_*.iter_*.D_usage.tsv` files of several samples 
into one table  
(Suppose `[iter_num]` is 9 (by default), `[allowed_possible_D_num]` is 99 (by default), and `<output_prefix>` are step2/sample1, step2/sample2, ...)

```bash
for allow_num in 99; do
    echo -ne "D\titer_0" > tmp.head
    ls step2/*.allow_${allow_num}.iter_9.D_usage.tsv | head -n1 | while read f; do
        cat $f | perl -ne '@F=split/\t/; if($F[0] eq "-"){ print $F[0]."\t0\n"; }else{ print $F[0]."\t1\n"; }' >tmp.body
    done
    ls step2/*.allow_${allow_num}.iter_9.D_usage.tsv | while read f; do
        g=${f##*/}
        g=${g%%.*}
        echo $g
        echo -ne "\t$g.iter_9.sum\t$g.iter_9.prob"  >>tmp.head
        mv tmp.body tmp
        paste tmp <(cut -f2-3 $f)  >tmp.body
    done
    echo >>tmp.head
    cat tmp.head tmp.body >step2/allow_${allow_num}.iter_9.merged_D_usage_summary.tsv
done
```

### Step 3a. annotate D for each VDJ read, and summarize read count for each combination of V and D (optional)

#### yyx_DinVDJ_matrix.20211221.pl
```
cat <HTGTS_VDJ_annotated.tsv> | yyx_DinVDJ_matrix.20211221.pl <output_prefix> <ref_D_usage.tsv>
	[allowed_possible_D_num (default: 99)] [bait_IGHJ]
```

Input: 

- `<HTGTS_VDJ_annotated.tsv>`  generated by yyx_annotate_HTGTS_VDJ_pipeline.20200219.py

- `<ref_D_usage.tsv>`  two columns: D, usage(%) \
  the output of step2 `yyx_reannotate_VDJ_mid_D_usage_iteration_pipeline.20200319.pl`,
  e.g. `step2/<output_prefix>.allow_99.iter_9.D_usage.tsv`

Options:

- `[allowed_possible_D_num]`  only deal with reads with the number of possibilities in mid_D_annotate no larger than this number
- `[bait_IGHJ]`  only deal with reads with bait_overlap_features on this specified IGHJ?

Output:

- `<output_prefix>.add_DinVDJ.tsv`
- `<output_prefix>.VH_DinVDJ.tsv`

### Step 3b. normalize to total reads and summarize the normalized read count for V/D usage (optional)

#### yyx_tlx_anno_bed.20220418.pl
```
perl scripts/yyx_tlx_anno_bed.20220418.pl <input.tlx> <V_RSS_40.bed>
	>input_annotated.tlx
```

Input:

- `<input.tlx>`  generated by HTGTS pipeline (<https://robinmeyers.github.io/transloc_pipeline/>)

- `<VDJ_RSS_40.bed>`  contains the genomic coordinate range near RSS for each V/D/J segment

Output:

- STDOUT, can be redirected like `>input_annotated.tlx` \
  append several columns to the input tlx file (`<input.tlx>`) as follows:
  
  - Bfeatures , Pfeatures , Jfeatures   (annotation of overlapping features in <anno.bed>)


#### yyx_summarize_VDJ_P_NP_and_Dusage.20220428.r
```
Rscript yyx_summarize_VDJ_P_NP_and_Dusage.20220428.r
	<input_annotated.tlx> <input_stats.txt> <D_usage.tsv> <V_anno.bed> <D_anno.bed> <output.tsv>
	[normalize_total_reads (default:100000) (NULL to skip normalization)]
```

Input:

- `<input_annotated.tlx>`  generated by `yyx_tlx_anno_bed.20220418.pl`
- `<input_stats.txt>`  the `xxx_result_stats.txt` file generated by HTGTS pipeline (<https://robinmeyers.github.io/transloc_pipeline/>), which contains the total read number (uncut + result)
- `<D_usage.tsv>`  the output of step2 `yyx_reannotate_VDJ_mid_D_usage_iteration_pipeline.20200319.pl`,
  e.g. `step2/<output_prefix>.allow_99.iter_9.D_usage.tsv`

- `<V_anno.bed>`  the output will follow the V order in this file
- `<D_anno.bed>`  the output will follow the D order in this file

Option:

- `[normalize_total_reads]`  normalized to ? total reads (default: 100,000); use 'NULL' to skip normalization

Output:

- `<output.tsv>` \
  headline, 5 columns: name , count , count\_P , count\_NP , count\_D\_in\_VDJ \
  then 5 lines: Total , Germline , Junction , DJ , VDJ \
  after that, the D lines \
  and finally, the V lines


#### reformat (optional)

```
cat <output.tsv>| perl -e '
@lines=<STDIN>;
@lines= map { s/[\r\n]+$//; $_; } @lines;
for($i=0; $i<@lines; $i++){
 @F=split(/\t/, $lines[$i]);
 if($F[0] eq "DJ"){ @G=split(/\t/, $lines[$i+1]); $F[4]=$G[4]; }
 if($F[0] eq "VDJ"){ $F[4]="NA"; @G=split(/\t/, $lines[$i-1]); }
 if($F[0] eq "name"){
  push(@F, "count_D_in_DJ_and_VDJ");
 }else{
  push(@F, $F[1] + $F[4]);
 }
 $lines[$i] = join("\t", @F);
 print join("\t", @F)."\n";
 if($F[0] eq "VDJ"){
  print join("\t", "VDJ%", ($F[1]+$G[1])==0 ? "NA" : $F[1]/($F[1]+$G[1]), "NA", "NA", "NA", $G[5]==0 ? "NA" : $F[1]/$G[5])."\n";
 }
}' >reformat.tsv
```

This reformatting perl in-line code can do:

- append a column of count\_D\_in\_DJ\_and\_VDJ
- insert a line of VDJ% after VDJ line
- sum up the count\_D\_in\_VDJ for DJ line



## Pipeline 2. annotate productivity according to observed part of each read

I annotate the productivity of each read that has both V and J parts, using the criteria similar to that in IgBLAST:

- If the observed V to J part is in-frame and without stop codon, then it is classified as productive = 'T';
- if it is out-of-frame, or in-frame but with stop codon, then it is classified as productive = 'F';
- or if it does not contain both V and J parts, then it has productive = '-'.

#### yyx_tlx_VDJ_P_NP.20220329.pl
```
perl yyx_tlx_VDJ_P_NP.20220329.pl <input.tlx> <ref.fa> <VDJ.bed> <V.fa> <J.fa> <J.aux>
	>output.tlx  2>output.log
```

Input:

- `<input.tlx>`  generated by HTGTS pipeline (<https://robinmeyers.github.io/transloc_pipeline/>)

- `<ref.fa>`  the reference genome fasta file for `<VDJ.bed>`

- `<VDJ.bed>`  the genomic coordinate range for each V/D/J segment, should match `<V.fa>` and `<J.fa>`

- `<V.fa>`  the fasta file of V segments, just like the one used in IgBLAST, \
  need to be starting from a complete codon, without leading sequence, without GAP sequence

- `<J.fa>`  the fasta file of J segments, just like the one used in IgBLAST

- `<J.aux>`  the optional file in IgBLAST to annotate J frame, 4 columns:

  - gene name  (e.g. JH1 , IGHJ1*01)
  - first coding frame start position (0-based)  (e.g. 0 , 1 , 2)
  - chain type  (e.g. JH , JK , JL ; I will ignore this column)
  - CDR3 end (e.g. 18 , 13 , 6 , 7 ; I will also ignore this column)

Output:

- STDOUT, can be redirected like `>output.tlx` \
  append several columns to the input tlx file (`<input.tlx>`) as follows:

  - pre , bait , mid , prey , post   (segmented sequences on each read in <input.tlx>)
  - Bfeature , Pfeature   (annotation of overlapping features in <VDJ.bed>)
  - Vpart , midO , Jpart   (extended V(D)J sequence)
  - InFrame , Stop , Productive



## Supporting scripts

### General utilities

#### `Yyx_check_col_num.pl`
```
Usage: perl Yyx_check_col_num.pl <files> ...
Options:
	-d STR	set delimiter (default: \t)
	-n INT	the number of head lines that will be checked
		(default: 4; -1 for all lines)

Version: 0.1.0 (2012-12-02)
Author: Adam Yongxin Ye @ CBI
```

This script can output the number of columns (or fields) for several lines head of each input file


#### `yyx_show_or_skip_or_retrieve_columns.20190128.py`
```
Usage: cat <input> | python3 yyx_show_or_skip_or_retrieve_columns.20190128.py <show|onlyshow|skip|retrieve> [column_pattern_1] [column_pattern_2] ...
```

This script can be used to 'show' the mapping of column index and column name (`<input>` should contain the headline of column names),
or 'retrieve' (or 'skip') columns with specified `[column_pattern]`, which supports regex expression.


### Process HTGTS tlx files

#### `yyx_tlx2bed.20200126.py`
```
Usage: cat <input.tlx> | python this.py <which_part>
Options:
   <which_part> can be: junction (default) | bait | prey
Output: STDOUT   bed format 6 columns
```

This script can convert tlx format to bed format, using the genomic coorindate (range) of 'junction', 'bait' or 'prey' for each read.


#### `yyx_sequence_segment_tlx.20181221.py`
```
Usage: cat <input.tlx> | python3 yyx_sequence_segment_tlx.20181221.py
Input: STDIN   <input.tlx>
    should have at least these columns:
      B_Qstart, B_Qend, Qstart, Qend, Seq
Output: STDOUT   append 5 columns
    pre  bait  mid  prey  post
```

This script can retrieve the sequences of pre, bait, mid, prey, and post, 
according to the relevant information (Columns B_Qstart, B_Qend, Qstart, Qend, and Seq) in the `<input.tlx>` file.


#### `yyx_annotate_tlx_with_intersectBedResults.20181223.py`
```
Usage: python3 yyx_annotate_tlx_with_intersectBedResults.20181223.py <input.tlx> <anno1.bed> [anno2.bed] ...
```

This script will merge the annotation information in `<anno1.bed>` (and `[anno2.bed]` ...) into the `<input.tlx>`, and output to STDOUT.


#### `yyx_annotate_tlx_midD_LCS.20190116.py` and `yyx_annotate_tlx_midD_LCS.20220429.pl`
```
Usage: cat <input.tlx> | python3 yyx_annotate_tlx_midD_LCS.20190116.py <D.fa> [score_cutoff (default:5)]
Input: STDIN   <input.tlx>
    should have at least these columns:
      B_Qstart, B_Qend, Qstart, Qend, Seq
Output: STDOUT   append 5+2 columns
    pre  bait  mid  prey  post   mid_D_score  mid_D_annotate
```
or
```
cat <input.tlx> | perl yyx_annotate_tlx_midD_LCS.20220429.pl <D.fa> [score_cutoff (default:5)]
Input: STDIN   <input.tlx>
    should have at least these columns:
      B_Qstart, B_Qend, Qstart, Qend, Seq
    or
      mid
Output: STDOUT   append (5)+2 columns
      pre  bait  mid  prey  post
      mid_D_score  mid_D_annotate

Version: 0.1.0 (2022-04-29)
Author: Adam Yongxin Ye @ BCH
```

This script uses longest continuous substring (LCS) algorithm, to align the 'mid' sequence in `<input.tlx>` 
 to reference D sequences recorded in `<D.fa>` (and their reverse complements, to distinguish D orientation).
We did mid sequence alignment to possible D segments, 
because when bait is on IGHJ and prey is on IGHV, the mid sequence may be on IGHD.

LCS algorithm does not allow any gaps or mismatches in D alignment.
Its score shows how many continuous base pairs exactly match between a query (mid of each read) and a subject sequence (reference D sequences in `<D.fa>`).
It will output this kind of mid_D annotation, only when the score >= `[score_cutoff]` (default:5); 
otherwise, just output '-'.


#### `yyx_uniq_count_and_merge.20190111.py`
```
Usage: python yyx_uniq_count_and_merge.20190111.py <empty_fill> <should_split_output> <output_prefix> <file1> <file2> [file3 ...]
  <file1> can be 'filename' or 'filename:key_col_idx' or 'filename:col1-col2,col3,...' or 'filename:col:fieldname_prefix'
  (should have headline, columns separated by '\t', key_col_idx is 1-based)
Output:
  <output_prefix>.log  =  STDERR
  <output_prefix>.tsv  (separated by '\t')
     shared_field(s) , count_in_file_1, append_fields_in_file_1, count_in_file_2, append_fields_in_file_2, ...
  <output_prefix>.1=???.tsv, <output_prefix>.1x2.tsv, <output_prefix>.1x2x3.tsv ...  if <should_split_output> = True
```

This script merges input `<file1>`, `<file2>`, ..., 
according to a part of their columns (key_col_idx, or col1-col2,col3,...,  as keys.

If `<should_split_output>` is set, then the output will be splitted into several files, 
 according to the row's occurrence in how many and which file.


#### `yyx_reannotate_calculate_mid_D_usage.20200319.pl`
```
Usage: cat <HTGTS_VDJ_annotated.tsv> | perl yyx_reannotate_calculate_mid_D_usage.20200319.pl <output_prefix> <mm9|mm9AJ>
	[allowed_possible_D_num (default: 0)] [ref_D_usage.tsv] [bait_IGHJ]
Input:
	[ref_D_usage.tsv]	two columns: D, usage(%)
Output:
	<output_prefix>.D_reannotated.tsv
	<output_prefix>.D_usage.tsv

Version: 0.1.2 (2020-03-19)
Author: Adam Yongxin Ye @ BCH
```

This script will reanalyze the input `<HTGTS_VDJ_annotated.tsv>` (generated by `yyx_annotate_HTGTS_VDJ_pipeline.20200219.py`): 
- only retrieve VDJ joins (bait overlapping IGHJ, and junction overlapping IGHV), thus discard DJ joins
- reannotate mid D assignment, by parsing Column mid_D_annotate, for each read;   
  count how many D segments (ignoring D orientation '(rC)') are among the best mid D alignment (denoted as 'possible_D_num'):
  - if possible_D_num = 1, just assign the read to that specific D segment;
  - if 1 < possible_D_num <= allowed_possible_D_num, then assign the read to these possible D segments 
    with fraction proportional to `[ref_D_usage.tsv]`;
  - if possible_D_num > allowed_possible_D_num, just set the mid D assignment to '-'.  
    (discard these reads in the next step of estimating D usage)
- estimate the (updated) D usage by summing over the D assignment of all the reads, 
  and then normalized to 1 (as the sum of D usage).

Options and known caveats:

- `<mm9|mm9AJ>` is an option to specify whether the mouse genome is mm9 (for C57BL/6) or mm9_AJ851868ins (for 129 mouse).  
For simple implementation, I hard-coded the names, aliases and output order of their D segments in `yyx_reannotate_calculate_mid_D_usage.20200319.pl`,
which need to be manually adjusted if applied to other strains or species.



#### `yyx_tlx_seq_seg_and_bed_anno.20220429.pl`
```
Usage: cat <input.tlx> | perl yyx_tlx_seq_seg_and_bed_anno.20220429.pl <anno.bed>
Output: STDOUT   append several columns as follows
	pre  bait  mid  prey  post
	junction_overlap_bps  junction_overlap_features
	prey_overlap_bps  prey_overlap_features
	bait_overlap_bps  bait_overlap_features

Version: 0.1.0 (2022-04-29)
Author: Adam Yongxin Ye @ BCH
```

This script can retrieve the sequences of pre, bait, mid, prey, and post, 
according to the relevant information (Columns B_Qstart, B_Qend, Qstart, Qend, and Seq) in the `<input.tlx>` file.
And annotate what features in `<anno.bed>` overlap with junction, prey, or bait


#### yyx_tlx_anno_bed.20220418.pl
```
Usage: yyx_tlx_anno_bed.20220418.pl <input.tlx> <anno.bed>
Output: STDOUT   append several columns as follows
	Bfeatures  Pfeatures  Jfeatures   (annotation of overlapping features in <anno.bed>)

Version: 0.1.0 (2022-04-18)
Author: Adam Yongxin Ye @ BCH
```

This script can annotate what features in `<anno.bed>` overlap with bait, prey, or junction


