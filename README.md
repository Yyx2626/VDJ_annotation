# VDJ_annotation
 scripts and pipeline for VDJ annotation of HTGTS tlx files, including iteratively estimate D usage in VDJ joins

Author: Adam Yongxin Ye @ Boston Children's Hospital / Harvard Medical School


## Setup

The scripts are command-line perl and python scripts, with little dependence on other packages, 
except for `yyx_annotate_tlx_midD_LCS.20190116.py`, which `import Bio.SeqIO` ([Biopython](https://biopython.org/)).

They should be able to run in any modern Linux or Mac platform;
or you might need to first install perl and python 3 for your platform.

To use the scripts, just download the scripts and put/unzipped in a folder.
You can rename the folder with any name you like, such as `VDJ_annotation_scripts`.

When executing the following two pipeline scripts, just replace the command-line argument `<scripts_dir>` with the path of the folder.


## Pipeline

### Step 1. annotate HTGTS tlx files

#### yyx_annotate_HTGTS_VDJ_pipeline.20200219.py
```
python3 yyx_annotate_HTGTS_VDJ_pipeline.20200219.py
	<VDJ_annotation.bed> <D.fa> <scripts_dir> <input.tlx> <output_prefix>
```

Input:

- `<input.tlx>`  generated by HTGTS pipeline (<https://robinmeyers.github.io/transloc_pipeline/>)

- `<scripts_dir>`  should contain the script files called by this pipeline

  - `Yyx_check_col_num.pl`
  - `yyx_tlx2bed.20200126.py`
  - `yyx_sequence_segment_tlx.20181221.py`
  - `yyx_annotate_tlx_with_intersectBedResults.20181223.py`
  - `yyx_annotate_tlx_midD_LCS.20190116.py`
  - `yyx_uniq_count_and_merge.20190111.py`
  - `yyx_show_or_skip_or_retrieve_columns.20190128.py`

- `<VDJ_annotation.bed>`  contains the genomic coordinate range for each V/D/J segment

  - will used by `yyx_annotate_tlx_with_intersectBedResults.20181223.py`

- `<D.fa>`  contains the sequences of D segments, for

  - will used by `yyx_annotate_tlx_midD_LCS.20190116.py`
  
Output:  (where `yyyyMMdd` is the executing date)

- `<output_prefix>.intersectBed_annotated.yyyyMMdd.tlx`

  will append columns of
  - pre, bait, mid, prey, post sequences
  - \*_overlap_bps and \*_overlap_features  for junction, prey and bait

- `<output_prefix>.annotate_tlx_midD_LCS.yyyyMMdd.tlx`

  will append columns of  pre, bait, mid, prey, post, mid_D_score, mid_D_annotate
  
  for mid_D_annotate column, '(rC)' means reverse complement (orientation of D in the read)

- `<output_prefix>.HTGTS_VDJ_annotated.yyyyMMdd.tsv`

  final output tsv (tab-separated values) format file
  
  compared to `<input.tlx>`, append 5+6+2=13 columns
  - pre, bait, mid, prey, post (sequences) : 5 columns
  - \*_overlap_bps and \*_overlap_features  for junction, prey and bait : 3\*2=6 columns
  - mid_D_score and mid_D_annotate : 2 columns

`yyx_annotate_HTGTS_VDJ_pipeline.20200219.py` will sequentially call:

- `Yyx_check_col_num.pl`  to check the number of columns of <input.tlx>

- `yyx_tlx2bed.20200126.py`  to convert tlx to bed format for junction, prey, and bait

  - Output: `<output_prefix>.*.yyyyMMdd.tmp.bed` and `<output_prefix>.*.yyyyMMdd.bed`  
    (these intermediate files will be automatically removed)

- `yyx_sequence_segment_tlx.20181221.py`  to retrieve the segmented sequence (pre, bait, mid, prey, post) for each read

  - Output: `<output_prefix>.sequence_segmented.yyyyMMdd.tlx`  
    (this intermediate file will be automatically removed)

- `yyx_annotate_tlx_with_intersectBedResults.20181223.py`  to annotate tlx junction/prey/bait overlapping with <VDJ_annotation.bed>

  - Output: `<output_prefix>.intersectBed_annotated.yyyyMMdd.tlx`

- `yyx_annotate_tlx_midD_LCS.20190116.py`  to annotate mid by align to <D.fa> by longest continuous substring (LCS) algorithm

  - Output: `<output_prefix>.annotate_tlx_midD_LCS.yyyyMMdd.tlx`

- `yyx_uniq_count_and_merge.20190111.py`  to merge the annotation results above

  - Output: `<output_prefix>.HTGTS_annotate_merged.yyyyMMdd.tsv`  
    (this intermediate file will be automatically removed)

- `yyx_show_or_skip_or_retrieve_columns.20190128.py`  to skip some useless columns and output the final output tsv file

  - Output: `<output_prefix>.HTGTS_VDJ_annotated.yyyyMMdd.tsv`


### Step 2. iteratively estimate D usage in VDJ joins

#### yyx_reannotate_VDJ_mid_D_usage_iteration_pipeline.20200319.pl
```
perl yyx_reannotate_VDJ_mid_D_usage_iteration_pipeline.20200319.pl
	<scripts_dir> <HTGTS_VDJ_annotated.tsv> <output_prefix> <mm9|mm9AJ>
	[iter_num (default:9)] [allowed_possible_D_num (default:99)]
	[init_ref_D_usage.tsv (default:even_probabilities]
```

Input: 

- `<HTGTS_VDJ_annotated.tsv>`  generated by yyx_annotate_HTGTS_VDJ_pipeline.20200219.py
- `[init_ref_D_usage.tsv]`  two columns: D, usage(%)

Output:

- `<output_prefix>.allow_*.iter_*.D_reannotated.tsv`
- `<output_prefix>.allow_*.iter_*.D_usage.tsv`

`yyx_reannotate_VDJ_mid_D_usage_iteration_pipeline.20200319.pl` will iteratively call 

- `yyx_reannotate_calculate_mid_D_usage.20200319.pl`  
  which will focus on VDJ joins (Column junction_overlap_features starts with IGHV), 
  assign ambiguous D segments according to  `[init_ref_D_usage.tsv]`,
  then sum up D assignment to estimate D usage in VDJ joins


Later, you may also use some bash loops like below, 
to rearrange the final `<output_prefix>.allow_*.iter_*.D_usage.tsv` files of several samples 
into one table  
(Suppose `[iter_num]` is 9 (by default), `[allowed_possible_D_num]` is 99 (by default), and `<output_prefix>` are step2/sample1, step2/sample2, ...)

```bash
for allow_num in 99; do
    echo -ne "D\titer_0" > tmp.head
    ls step2/*.allow_${allow_num}.iter_9.D_usage.tsv | head -n1 | while read f; do
        cat $f | perl -ne '@F=split/\t/; if($F[0] eq "-"){ print $F[0]."\t0\n"; }else{ print $F[0]."\t1\n"; }' >tmp.body
    done
    ls step2/*.allow_${allow_num}.iter_9.D_usage.tsv | while read f; do
        g=${f##*/}
        g=${g%%.*}
        echo $g
        echo -ne "\t$g.iter_9.sum\t$g.iter_9.prob"  >>tmp.head
        mv tmp.body tmp
        paste tmp <(cut -f2-3 $f)  >tmp.body
    done
    echo >>tmp.head
    cat tmp.head tmp.body >step2/allow_${allow_num}.iter_9.merged_D_usage_summary.tsv
done
```

## Scripts

### General utilities

#### `Yyx_check_col_num.pl`
```
Usage: perl Yyx_check_col_num.pl <files> ...
Options:
	-d STR	set delimiter (default: \t)
	-n INT	the number of head lines that will be checked
		(default: 4; -1 for all lines)

Version: 0.1.0 (2012-12-02)
Author: Adam Yongxin Ye @ CBI
```

This script can output the number of columns (or fields) for several lines head of each input file


#### `yyx_show_or_skip_or_retrieve_columns.20190128.py`
```
Usage: cat <input> | python3 yyx_show_or_skip_or_retrieve_columns.20190128.py <show|onlyshow|skip|retrieve> [column_pattern_1] [column_pattern_2] ...
```

This script can be used to 'show' the mapping of column index and column name (`<input>` should contain the headline of column names),
or 'retrieve' (or 'skip') columns with specified `[column_pattern]`, which supports regex expression.


### Process HTGTS tlx files

#### `yyx_tlx2bed.20200126.py`
```
Usage: cat <input.tlx> | python this.py <which_part>
Options:
   <which_part> can be: junction (default) | bait | prey
Output: STDOUT   bed format 6 columns
```

This script can convert tlx format to bed format, using the genomic coorindate (range) of 'junction', 'bait' or 'prey' for each read.


#### `yyx_sequence_segment_tlx.20181221.py`
```
Usage: cat <input.tlx> | python3 yyx_sequence_segment_tlx.20181221.py
Input: STDIN   <input.tlx>
    should have at least these columns:
      B_Qstart, B_Qend, Qstart, Qend, Seq
Output: STDOUT   append 5 columns
    pre  bait  mid  prey  post
```

This script can retrieve the sequences of pre, bait, mid, prey, and post, 
according to the relevant information (Columns B_Qstart, B_Qend, Qstart, Qend, and Seq) in the `<input.tlx>` file.


#### `yyx_annotate_tlx_with_intersectBedResults.20181223.py`
```
Usage: python3 yyx_annotate_tlx_with_intersectBedResults.20181223.py <input.tlx> <anno1.bed> [anno2.bed] ...
```

This script will merge the annotation information in `<anno1.bed>` (and `[anno2.bed]` ...) into the `<input.tlx>`, and output to STDOUT.


#### `yyx_annotate_tlx_midD_LCS.20190116.py`
```
Usage: cat <input.tlx> | python3 yyx_annotate_tlx_midD_LCS.20190116.py <D.fa> [score_cutoff (default:5)]
Input: STDIN   <input.tlx>
    should have at least these columns:
      B_Qstart, B_Qend, Qstart, Qend, Seq
Output: STDOUT   append 5+2 columns
    pre  bait  mid  prey  post   mid_D_score  mid_D_annotate
```

This script uses longest continuous substring (LCS) algorithm, to align the 'mid' sequence in `<input.tlx>` 
 to reference D sequences recorded in `<D.fa>` (and their reverse complements, to distinguish D orientation).
We did mid sequence alignment to possible D segments, 
because when bait is on IGHJ and prey is on IGHV, the mid sequence may be on IGHD.

LCS algorithm does not allow any gaps or mismatches in D alignment.
Its score shows how many continuous base pairs exactly match between a query and a subject sequence.
It will output this kind of mid_D annotation, only when the score >= `[score_cutoff]` (default:5); 
otherwise, just output '-'.


#### `yyx_uniq_count_and_merge.20190111.py`
```
Usage: python yyx_uniq_count_and_merge.20190111.py <empty_fill> <should_split_output> <output_prefix> <file1> <file2> [file3 ...]
  <file1> can be 'filename' or 'filename:key_col_idx' or 'filename:col1-col2,col3,...' or 'filename:col:fieldname_prefix'
  (should have headline, columns separated by '\t', key_col_idx is 1-based)
Output:
  <output_prefix>.log  =  STDERR
  <output_prefix>.tsv  (separated by '\t')
     shared_field(s) , count_in_file_1, append_fields_in_file_1, count_in_file_2, append_fields_in_file_2, ...
  <output_prefix>.1=???.tsv, <output_prefix>.1x2.tsv, <output_prefix>.1x2x3.tsv ...  if <should_split_output> = True
```

This script merges input `<file1>`, `<file2>`, ..., 
according to a part of their columns (key_col_idx, or col1-col2,col3,...,  as keys.

If `<should_split_output>` is set, then the output will be splitted into several files, 
 according to the row's occurrence in how many and which file.


#### `yyx_reannotate_calculate_mid_D_usage.20200319.pl`
```
Usage: cat <HTGTS_VDJ_annotated.tsv> | perl yyx_reannotate_calculate_mid_D_usage.20200319.pl <output_prefix> <mm9|mm9AJ>
	[allowed_possible_D_num (default: 0)] [ref_D_usage.tsv] [bait_IGHJ]
Input:
	[ref_D_usage.tsv]	two columns: D, usage(%)
Output:
	<output_prefix>.D_reannotated.tsv
	<output_prefix>.D_usage.tsv

Version: 0.1.2 (2020-03-19)
Author: Adam Yongxin Ye @ BCH
```

This script will reanalyze the input `<HTGTS_VDJ_annotated.tsv>` (generated by `yyx_annotate_HTGTS_VDJ_pipeline.20200219.py`): 
- only retrieve VDJ joins (bait overlapping IGHJ, and junction overlapping IGHV), thus discard DJ joins
- reannotate mid D assignment, by parsing Column mid_D_annotate, for each read;   
  count how many D segments (ignoring D orientation '(rC)') are among the best mid D alignment (denoted as 'possible_D_num'):
  - if possible_D_num = 1, just assign the read to that specific D segment;
  - if 1 < possible_D_num <= allowed_possible_D_num, then assign the read to these possible D segments 
    with fraction proportional to `[ref_D_usage.tsv]`;
  - if possible_D_num > allowed_possible_D_num, just set the mid D assignment to '-'.  
    (discard these reads in the next step of estimating D usage)
- estimate the (updated) D usage by summing over the D assignment of all the reads, 
  and then normalized to 1 (as the sum of D usage).

Options and known caveats:

`<mm9|mm9AJ>` is an option to specify whether the mouse genome is mm9 (for C57BL/6) or mm9_AJ851868ins (for 129 mouse).

For simple implementation, I hard-coded the names, aliases and output order of their D segments in `yyx_reannotate_calculate_mid_D_usage.20200319.pl`,
which need to be manually adjusted if applied to other strains or species.

